{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDDvl37ZNOW"
      },
      "source": [
        "# Welcome to ML Blog Tutorial 2 (Textual Data)\n",
        "\n",
        "This tutorial will present the application of four interpretability techniques in a machine learning task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvqS4nhYZa41"
      },
      "source": [
        "## Setup\n",
        "First, let's install few libraries we need!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCsDOUGDdwG_"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "!pip install eli5\n",
        "!pip install mlxtend==0.18.0\n",
        "!pip install transformers\n",
        "!pip install pip install scikit-multilearn\n",
        "!pip install transformers-interpret\n",
        "!pip install bertviz\n",
        "!pip install anchor-exp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0TF2WcTZh_P"
      },
      "source": [
        "## Initialise\n",
        "\n",
        "Then, we will fine-tune a trannsformer model (BERT) for detecting hate speech content in short texts! We will use the [ETHOS dataset](https://link.springer.com/article/10.1007/s40747-021-00608-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewddt4dkdlpb"
      },
      "outputs": [],
      "source": [
        "import lime.lime_text\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import maxabs_scale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will load our data"
      ],
      "metadata": {
        "id": "hRfyQ-kimE5H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h68cMllLeoc_"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/master/ethos/ethos_data/Ethos_Dataset_Binary.csv\"\n",
        "ethos = pd.read_csv(url,delimiter=';')\n",
        "x = ethos['comment'].values\n",
        "y = [1 if i >= 0.5 else 0 for i in ethos['isHate'].values]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split our data in train/test/valitdation sets"
      ],
      "metadata": {
        "id": "7NRv6C9BmJnI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tkF4i5MN7Qo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts_o, test_texts, train_labels_o, test_labels = train_test_split(x, y, stratify=y, test_size=0.1, random_state=42)\n",
        "size = (0.05 * len(y)) / len(train_labels_o)\n",
        "train_texts, validation_texts, train_labels, validation_labels = train_test_split(list(train_texts_o), train_labels_o, stratify=train_labels_o, test_size=size, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We finne tune our Bert (Base Cased) model"
      ],
      "metadata": {
        "id": "My0OwwtWmOIy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brrdbFseen5V"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, utils, BertTokenizerFast\n",
        "from transformers.models.bert import BertForSequenceClassification\n",
        "from torch.utils.data import Dataset as TDataset\n",
        "from torch import tensor\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "\tevaluation_strategy='epoch', save_strategy='epoch', logging_strategy='epoch', log_level='warning',\n",
        "\toutput_dir='./results', num_train_epochs=3, warmup_steps=200, load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "from transformers import BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
        "\n",
        "class myDataset(TDataset):\n",
        "\tdef __init__(self, encodings, labels, tokenizer):\n",
        "\t\tself.encodings = tokenizer(list(encodings), truncation=True, padding=True)\n",
        "\t\tself.labels = labels\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\titem = {key: tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\t\titem['labels'] = tensor(self.labels[idx])\n",
        "\t\treturn item\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.labels)\n",
        "\n",
        "train_dataset = myDataset(train_texts, train_labels, tokenizer)\n",
        "validation_dataset = myDataset(validation_texts, validation_labels, tokenizer)\n",
        "test_dataset = myDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", output_attentions=True, output_hidden_states=False)\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=validation_dataset)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the performance of the model in the train/test sets"
      ],
      "metadata": {
        "id": "GPChgG1tmUDJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B09xQYJBjMER"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "hidden_states = []\n",
        "for instance in train_texts_o:\n",
        "    temp_dataset = myDataset([instance],[0],tokenizer)\n",
        "    output = trainer.predict(temp_dataset)\n",
        "    predictions.append(list(output[0][0][0]))\n",
        "    hidden_states.append(output[0][1][-1][0][0].shape)\n",
        "train_predictions = [1 if i[1]>=0 else 0 for i in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sRvOD1ynxEE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "print('Balanced Accuracy: ', balanced_accuracy_score(train_labels_o, train_predictions))\n",
        "print('F1 weighted:       ', f1_score(train_labels_o, train_predictions, average='weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKU2nwWQnrap"
      },
      "outputs": [],
      "source": [
        "test_predictions = []\n",
        "test_hidden_states = []\n",
        "for instance in test_texts:\n",
        "    temp_dataset = myDataset([instance],[0],tokenizer)\n",
        "    output = trainer.predict(temp_dataset)\n",
        "    test_predictions.append(list(output[0][0][0]))\n",
        "    test_hidden_states.append(output[0][1][-1][0][0].shape)\n",
        "test_predictions2 = [1 if i[1]>=0 else 0 for i in test_predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0iIjreNovE-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "print('Balanced Accuracy: ', balanced_accuracy_score(test_labels, test_predictions2))\n",
        "print('F1 weighted:       ', f1_score(test_labels, test_predictions2, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Xug-XdZxKo"
      },
      "source": [
        "## Explain an example\n",
        "\n",
        "Finally, we will use few techniques to explain a random instance (instance x_test[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKB3aLD9op3C"
      },
      "outputs": [],
      "source": [
        "from lime.lime_text import LimeTextExplainer\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "from anchor.anchor_text import AnchorText\n",
        "from bertviz import model_view, head_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz53KtfJZ633"
      },
      "source": [
        "We will start with LIME! LIME provides weights (feature importance) as explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NVXAif7O-Zl"
      },
      "outputs": [],
      "source": [
        "instance = test_texts[46] + ''\n",
        "print(instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saIQsKs5eUfe"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "def predictor(texts):\n",
        "  all_probabilities = []\n",
        "  splits = np.array_split(texts, 100)\n",
        "  for split in splits:\n",
        "    split_labels = [0] * len(split)\n",
        "    dataset = myDataset(split, split_labels, tokenizer)\n",
        "    logits, _ = trainer.predict(dataset)[0]\n",
        "    probabilities = softmax(logits, axis=1)\n",
        "    all_probabilities.extend(probabilities)\n",
        "  return np.array(all_probabilities)\n",
        "\n",
        "lime_explainer = LimeTextExplainer(class_names=['No Hate Speech','Hate Speech'], split_expression='\\s+', bow=False)\n",
        "exp = lime_explainer.explain_instance(instance, predictor, num_samples=1000)#4,\n",
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUjXW6a2aMNb"
      },
      "source": [
        "Then, we will use Anchors, which provides a rule as an anchor interpretation! (This one is very slow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PQnnQmF_l90"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "def predictor_anchors(texts):\n",
        "  all_probabilities = []\n",
        "  splits = np.array_split(texts, 1)\n",
        "  for split in splits:\n",
        "    split_labels = [0] * len(split)\n",
        "    dataset = myDataset(split, split_labels, tokenizer)\n",
        "    logits, _ = trainer.predict(dataset)[0]\n",
        "    probabilities = [np.argmax(i) for i in softmax(logits, axis=1)]\n",
        "    all_probabilities.extend(probabilities)\n",
        "  return np.array(all_probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "explainer = AnchorText(nlp, ['No Hate Speech','Hate Speech'], use_unk_distribution=True, mask_string='love')\n",
        "text = instance\n",
        "pred = explainer.class_names[predictor_anchors([text])[0]]\n",
        "alternative =  explainer.class_names[1 - predictor_anchors([text])[0]]\n",
        "print('Prediction: %s' % pred)\n",
        "exp = explainer.explain_instance(text, predictor_anchors, threshold=0.90)"
      ],
      "metadata": {
        "id": "GpyL1QLpNenI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
        "print('Precision: %.2f' % exp.precision())\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % pred)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(only_same_prediction=True)]))\n",
        "print()\n",
        "print('Examples where anchor applies and model predicts %s:' % alternative)\n",
        "print()\n",
        "print('\\n'.join([x[0] for x in exp.examples(partial_index=0, only_different_prediction=True)]))"
      ],
      "metadata": {
        "id": "kk35hIOqNfo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxAaJ7jIBNIJ"
      },
      "outputs": [],
      "source": [
        "exp.show_in_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTYZ3BtlZ9Wb"
      },
      "source": [
        "Then, we will use Integrated Gradients (IG)! Like LIME, IG provides weights (feature importance) as explanations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgmbFbfSeUbj"
      },
      "outputs": [],
      "source": [
        "ig_explainer = SequenceClassificationExplainer(trainer.model, tokenizer, custom_labels=['No Hate Speech','Hate Speech'])\n",
        "ig_explainer(instance, index=1, n_steps=100)[1:-1]\n",
        "ig_explainer.visualize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p07MAUOaVoB"
      },
      "source": [
        "Finally, we will use BertViz to visualise the Attention Information! We start with the head view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOa2YsN_Q0Uh"
      },
      "outputs": [],
      "source": [
        "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
        "\n",
        "instance_dataset = myDataset([instance],[0],tokenizer)\n",
        "outputs = trainer.predict(instance_dataset)\n",
        "attention = tensor(np.array(list(outputs[0][1])))\n",
        "tokens = ['CLS'] + tokenizer.tokenize(instance) + ['SEP']\n",
        "head_view(attention[:,:,:,:,:], tokens,prettify_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And this is how BerViz visualizes attention through model_view"
      ],
      "metadata": {
        "id": "Vkt4gm4FmxmB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIsEGPx0aS8O"
      },
      "outputs": [],
      "source": [
        "model_view(attention[:,:,:,1:-1,1:-1], tokens[1:-1], display_mode='light')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tvqS4nhYZa41"
      ],
      "name": "ML Blog 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}